"""
Rationale generation module for credit score intelligence.

This module uses LLMs to generate human-readable explanations
for credit score predictions and model decisions.
"""

import json
import os
import logging
from typing import Dict, Any, List, Optional
import pandas as pd
import numpy as np
from datetime import datetime

# LangChain imports
from langchain_core.prompts import PromptTemplate
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# Set up logging
logger = logging.getLogger(__name__)


def generate_rationale_from_shap(shap_data: Dict[str, Any], 
                                prediction: str,
                                feature_names: List[str]) -> str:
    """
    Generate a human-readable rationale from SHAP values and prediction.
    
    Args:
        shap_data: Dictionary containing SHAP analysis data
        prediction: Predicted credit score category
        feature_names: List of feature names
        
    Returns:
        Generated rationale text
    """
    logger.info("Generating rationale from SHAP values...")
    
    # Extract key information
    max_positive = shap_data.get('max_positive_contributor', {})
    max_negative = shap_data.get('max_negative_contributor', {})
    total_shap = shap_data.get('total_shap_value', 0)
    
    # Create rationale based on prediction and SHAP values
    rationale_parts = []
    
    # Start with prediction context
    rationale_parts.append(f"Based on the analysis, your credit score is predicted to be **{prediction}**.")
    
    # Add explanation based on total SHAP value
    if total_shap > 0.1:
        rationale_parts.append("The overall assessment is positive, indicating strong creditworthiness.")
    elif total_shap < -0.1:
        rationale_parts.append("The overall assessment shows some areas of concern that may impact your credit score.")
    else:
        rationale_parts.append("The assessment is relatively neutral, with mixed factors influencing your credit score.")
    
    # Add specific feature explanations
    if max_positive:
        feature = max_positive.get('feature', 'Unknown')
        value = max_positive.get('value', 0)
        rationale_parts.append(f"**Key positive factor**: {feature} contributes significantly (+{value:.3f}) to your credit score.")
    
    if max_negative:
        feature = max_negative.get('feature', 'Unknown')
        value = max_negative.get('value', 0)
        rationale_parts.append(f"**Area for improvement**: {feature} has a negative impact ({value:.3f}) on your credit score.")
    
    # Add general recommendations
    rationale_parts.append("\n**Recommendations:**")
    rationale_parts.append("- Maintain consistent payment history")
    rationale_parts.append("- Keep credit utilization below 30%")
    rationale_parts.append("- Monitor your credit report regularly")
    rationale_parts.append("- Consider diversifying your credit mix")
    
    rationale = "\n\n".join(rationale_parts)
    logger.info("Rationale generated successfully")
    return rationale


def generate_llm_rationale(shap_data: Dict[str, Any], 
                          prediction: str,
                          feature_values: Dict[str, float]) -> str:
    """
    Generate rationale using LLM (placeholder implementation).
    
    Args:
        shap_data: Dictionary containing SHAP analysis data
        prediction: Predicted credit score category
        feature_values: Dictionary of feature values for the sample
        
    Returns:
        Generated rationale text
    """
    logger.info("Generating LLM-based rationale...")
    
    # For now, use the SHAP-based rationale
    # In a real implementation, this would call an LLM API
    feature_names = list(feature_values.keys())
    rationale = generate_rationale_from_shap(shap_data, prediction, feature_names)
    
    # Add LLM-style formatting
    llm_rationale = f"""
# Credit Score Analysis Report

## Prediction: {prediction}

{rationale}

## Technical Details
- Analysis based on SHAP (SHapley Additive exPlanations) values
- Model confidence: High
- Data points analyzed: {len(feature_values)}

---
*This analysis is generated by our AI-powered credit scoring system.*
"""
    
    logger.info("LLM rationale generated successfully")
    return llm_rationale.strip()


def load_shap_data(file_path: str) -> Optional[Dict[str, Any]]:
    """
    Load SHAP data from JSON file.
    
    Args:
        file_path: Path to the SHAP JSON file
        
    Returns:
        Dictionary containing SHAP data or None if file not found
    """
    try:
        if os.path.exists(file_path):
            with open(file_path, 'r') as f:
                return json.load(f)
        else:
            logger.warning(f"SHAP data file not found: {file_path}")
            return None
    except Exception as e:
        logger.error(f"Error loading SHAP data: {str(e)}")
        return None


def create_sample_rationale(prediction: str, 
                          feature_values: Dict[str, float]) -> str:
    """
    Create a sample rationale when SHAP data is not available.
    
    Args:
        prediction: Predicted credit score category
        feature_values: Dictionary of feature values
        
    Returns:
        Sample rationale text
    """
    logger.info("Creating sample rationale...")
    
    # Analyze key features
    income = feature_values.get('Income', 0)
    credit_utilization = feature_values.get('Credit_Utilization_Ratio', 0)
    age = feature_values.get('Age', 0)
    
    rationale_parts = []
    rationale_parts.append(f"Your credit score is predicted to be **{prediction}**.")
    
    # Income analysis
    if income > 75000:
        rationale_parts.append("Your income level is strong, which positively impacts your creditworthiness.")
    elif income > 40000:
        rationale_parts.append("Your income level is moderate, providing a solid foundation for credit.")
    else:
        rationale_parts.append("Your income level may limit your credit options, but other factors can help improve your score.")
    
    # Credit utilization analysis
    if credit_utilization < 0.3:
        rationale_parts.append("Your credit utilization is excellent (below 30%), which is ideal for credit scoring.")
    elif credit_utilization < 0.5:
        rationale_parts.append("Your credit utilization is good, but consider reducing it further for optimal scoring.")
    else:
        rationale_parts.append("Your credit utilization is high, which negatively impacts your credit score. Focus on paying down balances.")
    
    # Age analysis
    if age > 30:
        rationale_parts.append("Your age and experience level provide stability to your credit profile.")
    else:
        rationale_parts.append("As a younger individual, focus on building a strong credit history over time.")
    
    rationale_parts.append("\n**Key Recommendations:**")
    rationale_parts.append("- Pay all bills on time")
    rationale_parts.append("- Keep credit card balances low")
    rationale_parts.append("- Don't apply for too much credit at once")
    rationale_parts.append("- Monitor your credit report regularly")
    
    return "\n\n".join(rationale_parts)


def create_shap_summary_text(shap_data: Dict[str, Any]) -> str:
    """
    Create a text summary of SHAP values for LLM processing.
    
    Args:
        shap_data: Dictionary containing SHAP analysis data
        
    Returns:
        Formatted text summary of SHAP values
    """
    feature_values = shap_data.get('feature_values', {})
    shap_values = shap_data.get('shap_values', [])
    feature_names = shap_data.get('feature_names', [])
    
    # Create summary text
    summary_parts = []
    summary_parts.append("SHAP Feature Importance Analysis:")
    summary_parts.append("=" * 40)
    
    # Sort features by absolute SHAP value
    feature_importance = []
    for i, (feature, value) in enumerate(zip(feature_names, shap_values)):
        feature_importance.append((feature, value, feature_values.get(feature, 0)))
    
    feature_importance.sort(key=lambda x: abs(x[1]), reverse=True)
    
    # Add top features
    summary_parts.append("\nTop Contributing Factors:")
    for feature, shap_val, actual_val in feature_importance[:8]:  # Top 8 features
        impact = "Positive" if shap_val > 0 else "Negative"
        summary_parts.append(f"- {feature}: {impact} impact ({shap_val:.3f}) | Current value: {actual_val}")
    
    # Add overall assessment
    total_shap = shap_data.get('total_shap_value', 0)
    if total_shap > 0.1:
        summary_parts.append(f"\nOverall Assessment: Strong positive factors (Total SHAP: +{total_shap:.3f})")
    elif total_shap < -0.1:
        summary_parts.append(f"\nOverall Assessment: Some concerning factors (Total SHAP: {total_shap:.3f})")
    else:
        summary_parts.append(f"\nOverall Assessment: Mixed factors (Total SHAP: {total_shap:.3f})")
    
    return "\n".join(summary_parts)


def generate_llm_rationale_with_langchain(shap_data: Dict[str, Any], 
                                         prediction: str,
                                         api_key: str = None,
                                         model_name: str = "gpt-3.5-turbo") -> str:
    """
    Generate rationale using LangChain with OpenAI.
    
    Args:
        shap_data: Dictionary containing SHAP analysis data
        prediction: Predicted credit score category
        api_key: OpenAI API key (if None, will try to get from environment)
        model_name: OpenAI model to use
        
    Returns:
        Generated rationale text
    """
    logger.info("Generating LLM rationale with LangChain...")
    
    try:
        # Get API key
        if api_key is None:
            api_key = os.getenv('OPENAI_API_KEY')
            if not api_key:
                logger.warning("No OpenAI API key found. Using fallback rationale.")
                return generate_rationale_from_shap(shap_data, prediction, shap_data.get('feature_names', []))
        
        # Create SHAP summary
        shap_summary = create_shap_summary_text(shap_data)
        
        # Create prompt template
        prompt_template = PromptTemplate(
            input_variables=["shap_summary", "prediction"],
            template="""
Given SHAP feature importances for a credit score prediction:

{shap_summary}

The predicted credit score category is: {prediction}

Explain in plain English why this credit score category was predicted.
Provide 2–3 actionable financial improvement suggestions.

Format your response as a clear, professional explanation that a consumer can understand.
"""
        )
        
        # Initialize LLM
        llm = ChatOpenAI(
            openai_api_key=api_key,
            model_name=model_name,
            temperature=0.7,
            max_tokens=500
        )
        
        # Generate rationale
        prompt = prompt_template.format(
            shap_summary=shap_summary,
            prediction=prediction
        )
        
        response = llm.invoke([HumanMessage(content=prompt)])
        rationale = response.content
        
        logger.info("LLM rationale generated successfully")
        return rationale
        
    except Exception as e:
        logger.error(f"Error generating LLM rationale: {str(e)}")
        logger.info("Falling back to rule-based rationale")
        return generate_rationale_from_shap(shap_data, prediction, shap_data.get('feature_names', []))


def save_rationale_to_file(rationale: str, 
                          output_path: str = None,
                          sample_id: str = "sample_001") -> str:
    """
    Save generated rationale to a text file.
    
    Args:
        rationale: Generated rationale text
        output_path: Path to save the file (optional)
        sample_id: Sample identifier for filename
        
    Returns:
        Path to the saved file
    """
    if output_path is None:
        # Create output directory
        output_dir = "outputs/rationales"
        os.makedirs(output_dir, exist_ok=True)
        
        # Generate filename with timestamp
        timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        output_path = os.path.join(output_dir, f"{sample_id}_{timestamp}.txt")
    
    # Ensure output directory exists
    os.makedirs(os.path.dirname(output_path), exist_ok=True)
    
    # Save rationale
    with open(output_path, 'w', encoding='utf-8') as f:
        f.write(f"Credit Score Rationale - {sample_id}\n")
        f.write("=" * 50 + "\n\n")
        f.write(f"Generated on: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(rationale)
    
    logger.info(f"Rationale saved to: {output_path}")
    return output_path


def generate_rationale_pipeline(shap_json_path: str = "outputs/shap_summaries/sample_shap.json",
                               prediction: str = "Good",
                               api_key: str = None,
                               sample_id: str = "sample_001") -> Dict[str, Any]:
    """
    Complete rationale generation pipeline.
    
    Args:
        shap_json_path: Path to SHAP JSON file
        prediction: Predicted credit score category
        api_key: OpenAI API key
        sample_id: Sample identifier
        
    Returns:
        Dictionary containing rationale generation results
    """
    logger.info("Starting rationale generation pipeline...")
    
    # Load SHAP data
    shap_data = load_shap_data(shap_json_path)
    if shap_data is None:
        logger.warning("No SHAP data found. Creating sample rationale.")
        feature_values = {
            'Income': 50000,
            'Credit_Utilization_Ratio': 0.3,
            'Age': 35,
            'Credit_History_Length': 5
        }
        rationale = create_sample_rationale(prediction, feature_values)
    else:
        # Generate LLM rationale
        rationale = generate_llm_rationale_with_langchain(shap_data, prediction, api_key)
    
    # Save rationale to file
    output_path = save_rationale_to_file(rationale, sample_id=sample_id)
    
    # Prepare results
    results = {
        'rationale': rationale,
        'output_path': output_path,
        'sample_id': sample_id,
        'prediction': prediction,
        'shap_data_used': shap_data is not None
    }
    
    logger.info("Rationale generation pipeline completed successfully!")
    return results